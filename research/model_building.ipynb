{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\MLOps-Project\\\\text-to-speech-using-mlops'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelBuildingConfig:\n",
    "    root_dir : Path\n",
    "    text_num_embeddings : int\n",
    "    embedding_size : int\n",
    "    encoder_embedding_size  : int\n",
    "    dim_feedforward : int\n",
    "    postnet_embedding_size : int\n",
    "    encoder_kernel_size : int\n",
    "    postnet_kernel_size : int\n",
    "    num_heads : int\n",
    "    dropout : float\n",
    "    batch_first : bool\n",
    "    mel_freq : int\n",
    "    max_mel_time : int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.simpletts.constants import *\n",
    "from src.simpletts.utils.common import create_directories, read_yaml\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "        \n",
    "    def get_model_building_config(self) -> ModelBuildingConfig:\n",
    "        config = self.config.model_building\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_building_config = ModelBuildingConfig(\n",
    "            root_dir= self.config.root_dir,\n",
    "            text_num_embeddings = self.params.text_num_embeddings,\n",
    "            embedding_size = self.params.embedding_size,\n",
    "            encoder_embedding_size = self.params.encoder_embedding_size,\n",
    "            dim_feedforward = self.params.dim_feedforward,\n",
    "            postnet_embedding_size = self.params.postnet_embedding_size,\n",
    "            encoder_kernel_size = self.params.encoder_kernel_size,\n",
    "            postnet_kernel_size = self.params.postnet_kernel_size,\n",
    "            dropout=self.params.dorout,\n",
    "            num_heads=self.params.num_heads,\n",
    "            batch_first = self.params.batch_first,\n",
    "            mel_freq = self.params.mel_freq,\n",
    "            max_mel_time = self.params.max_mel_time\n",
    "        )\n",
    "        \n",
    "        return model_building_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, config : ModelBuildingConfig):\n",
    "        self.config = config\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(\n",
    "            normalized_shape=self.config.embedding_size,\n",
    "            num_heads = self.config.num_heads,\n",
    "            dropout = self.config.dropout,\n",
    "            batch_first = self.config.batch_first\n",
    "        )\n",
    "        \n",
    "        self.dropout1 = torch.nn.Dropout(self.config.dropout)\n",
    "        self.norm2 = nn.LayerNorm(\n",
    "            normalized_shape=self.config.embedding_size\n",
    "        )\n",
    "        \n",
    "        self.linear1 = nn.Linear(\n",
    "            self.config.embedding_size,\n",
    "            self.config.dim_feedforward\n",
    "        )\n",
    "        \n",
    "        self.dropout2 = torch.nn.Dropout(self.config.dropout)\n",
    "        self.linear2 = nn.Linear(\n",
    "            self.config.dim_feedforward,\n",
    "            self.config.embedding_size\n",
    "        )\n",
    "        self.dropout3 = torch.nn.Dropout(self.config.dropout)\n",
    "        \n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        attn_mask = None,\n",
    "        key_padding_mask  = None\n",
    "    ):\n",
    "        x_out = self.norm1(x)\n",
    "        x_out, _ = self.attn(\n",
    "            query = x_out,\n",
    "            key = x_out,\n",
    "            value = x_out,\n",
    "            attn_mask  = attn_mask,\n",
    "            key_padding_mask = key_padding_mask\n",
    "        )\n",
    "        x_out = self.dropout1(x_out)\n",
    "        x = x + x_out\n",
    "        \n",
    "        x_out = self.norm2(x)\n",
    "        x_out  = F.relu(x_out)\n",
    "        x_out = self.dropout2(x_out)\n",
    "        x_out = self.linear2(x_out)\n",
    "        x_out = self.dropout3(x_out)\n",
    "        \n",
    "        x = x + x_out\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlcok(nn.Module):\n",
    "    def __init__(self, config : ModelBuildingConfig):\n",
    "        self.config = config\n",
    "        super(DecoderBlcok, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(\n",
    "            normalized_shape=self.config.embedding_size\n",
    "        )\n",
    "        self.self_attn = torch.nn.MultiheadAttention(\n",
    "            embed_dim=self.config.embedding_size,\n",
    "            num_heads=self.config.num_heads,\n",
    "            dropout=self.config.dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.dropout1 = torch.nn.Dropout(self.config.dropout)\n",
    "        \n",
    "        self.norm2 = nn.LayerNorm(\n",
    "            normalized_shape=self.config.embedding_size\n",
    "        )\n",
    "        self.attn = torch.nn.MultiheadAttention(\n",
    "            embed_dim=self.config.embedding_size,\n",
    "            num_heads= self.config.num_heads,\n",
    "            dropout=self.config.num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.dropout2 = torch.nn.Dropout(self.config.dropout)\n",
    "        self.nomr3 = nn.LayerNorm(\n",
    "            normalized_shape=self.config.embedding_size\n",
    "        )\n",
    "        \n",
    "        self.liner1 = nn.Linear(\n",
    "            self.config.embedding_size,\n",
    "            self.config.dim_feedforward\n",
    "        )\n",
    "        self.dropout3 = torch.dropout(self.config.dropout)\n",
    "        self.liner2 = nn.Linear(\n",
    "            self.config.dim_feedforward,\n",
    "            self.config.embedding_size\n",
    "        )        \n",
    "        \n",
    "        self.dropout4 = torch.nn.Dropout(self.config.dropout)\n",
    "        \n",
    "    def forward(self,\n",
    "                x,\n",
    "                memory,\n",
    "                x_attn_mask = None,\n",
    "                x_key_mask = None,\n",
    "                memory_attn_mask = None,\n",
    "                memory_key_padding_mask = None,\n",
    "                ):\n",
    "        x_out,_ = self.self_attn(\n",
    "            query = x,\n",
    "            key = x,\n",
    "            value = x,\n",
    "            attn_mask = x_attn_mask,\n",
    "            key_padding_mask = x_key_mask\n",
    "        )\n",
    "        x_out = self.dropout1(x_out)\n",
    "        x = self.norm1(x + x_out)\n",
    "        \n",
    "        x_out, _ = self.attn(\n",
    "            query = x,\n",
    "            key = memory,\n",
    "            value = memory,\n",
    "            attn_mask = memory_attn_mask,\n",
    "            key_padding_mask = memory_key_padding_mask\n",
    "        )\n",
    "        x_out  = self.dropout2(x_out)\n",
    "        x = self.norm2(x + x_out)\n",
    "        \n",
    "        x_out = self.liner1(x)\n",
    "        x_out = F.relu(x_out)\n",
    "        x_out = self.dropout3(x_out)\n",
    "        x_out = self.liner2(x_out)\n",
    "        x = self.nomr3(x + x_out)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderPreNet(nn.Module):\n",
    "    def __init__(self, config = ModelBuildingConfig):\n",
    "        self.config = config\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.embedding =  nn.Embedding(\n",
    "            num_embeddings=self.config.text_num_embeddings,\n",
    "            embedding_dim= self.config.encoder_embedding_size\n",
    "        )\n",
    "        \n",
    "        self.linear_1 = nn.Linear(\n",
    "            self.config.embedding_size,\n",
    "            self.config.encoder_embedding_size\n",
    "        )\n",
    "        \n",
    "        self.linear_2 = nn.Linear(\n",
    "            self.config.encoder_embedding_size,\n",
    "            self.config.embedding_size\n",
    "        )\n",
    "        self.conv_1 = nn.Conv2d(\n",
    "            self.config.encoder_embedding_size,\n",
    "            self.config.encoder_embedding_size,\n",
    "            kernel_size=self.config.encoder_kernel_size,\n",
    "            stride=1,\n",
    "            padding = int((self.config.encoder_kernel_size - 1) / 2),\n",
    "            dilation=1\n",
    "            \n",
    "        )\n",
    "        self.bn_1 = nn.BatchNorm1d(\n",
    "            self.config.encoder_embedding_size\n",
    "        )\n",
    "        self.dropout_1 = torch.nn.Dropout(self.config.dropout)\n",
    "        \n",
    "        self.conv_2 = nn.Conv1d(\n",
    "            self.config.encoder_embedding_size,\n",
    "            self.config.encoder_embedding_size,\n",
    "            kernel_size=self.config.encoder_kernel_size,\n",
    "            stride= 1,\n",
    "            padding= int((self.config.encoder_kernel_size -1) / 2),\n",
    "            dilation=1\n",
    "        )\n",
    "        self.bn_2 = nn.BatchNorm1d(\n",
    "            self.config.encoder_embedding_size\n",
    "        )\n",
    "        self.dropout_2 = torch.nn.Dropout(self.config.dropout)\n",
    "        self.conv_3 = nn.Conv1d(\n",
    "            self.config.encoder_embedding_size,\n",
    "            self.config.embedding_size,\n",
    "            kernel_size=self.config.encoder_kernel_size,\n",
    "            stride=1,\n",
    "            padding=int((self.config.encoder_kernel_size - 1) / 2),\n",
    "            dilation=1\n",
    "        )\n",
    "        self.bn_3 = nn.BatchNorm1d(\n",
    "            self.config.encoder_embedding_size\n",
    "        )\n",
    "        \n",
    "        self.dropout_3 = nn.Dropout(self.config.dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self,text):\n",
    "        x = self.embedding(text)\n",
    "        x = self.linear_1(x)\n",
    "        \n",
    "        x = x.transpose(2,1)\n",
    "        \n",
    "        x = self.conv_1(x)\n",
    "        x = self.bn_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_1(x)\n",
    "        \n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_2(x)\n",
    "        \n",
    "        \n",
    "        x = self.conv_3(x)\n",
    "        x = self.bn_3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_3(x)\n",
    "        \n",
    "        x = x.transpose(2,1)\n",
    "        x = self.linear_2(x)\n",
    "        \n",
    "        return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostNet(nn.Module):\n",
    "    def __init__(self, config : ModelBuildingConfig):\n",
    "        self.config = config\n",
    "        \n",
    "        super(PostNet, self).__init__()\n",
    "        self.conv_1 = nn.Conv1d(\n",
    "            self.config.mel_freq,\n",
    "            self.config.postnet_embedding_size,\n",
    "            kernel_size=self.config.postnet_kernel_size,\n",
    "            stride=1,\n",
    "            padding= int((self.config.postnet_kernel_size - 1) / 2),\n",
    "            dilation=1\n",
    "        )\n",
    "        self.bn_1 = nn.BatchNorm1d(\n",
    "            self.config.postnet_embedding_size\n",
    "        )\n",
    "        self.dropout_1 = torch.nn.Dropout(self.config.dropout)\n",
    "        \n",
    "        self.conv_2 = nn.Conv1d(\n",
    "            self.config.mel_freq,\n",
    "            self.config.postnet_embedding_size,\n",
    "            kernel_size=self.config.postnet_kernel_size,\n",
    "            stride=1,\n",
    "            padding=int((self.config.postnet_kernel_size - 1) / 2),\n",
    "            dilation= 1\n",
    "        )\n",
    "        self.bn_2 = nn.BatchNorm1d(\n",
    "            self.config.postnet_embedding_size\n",
    "        )\n",
    "        self.dropout_2 = nn.Dropout(self.config.dropout)\n",
    "        \n",
    "        self.conv_3 = nn.Conv1d(\n",
    "            self.config.mel_freq,\n",
    "            self.config.postnet_embedding_size,\n",
    "            kernel_size=self.config.postnet_kernel_size,\n",
    "            stride=1,\n",
    "            padding= int((self.config.postnet_kernel_size - 1) / 2),\n",
    "            dilation=1\n",
    "        )\n",
    "        self.bn_3 = nn.BatchNorm1d(\n",
    "            self.config.postnet_embedding_size\n",
    "        )\n",
    "        self.dropout_3  = nn.Dropout(self.config.dropout)\n",
    "        \n",
    "        self.conv_4 = nn.Conv1d(\n",
    "            self.config.mel_freq,\n",
    "            self.config.postnet_embedding_size,\n",
    "            kernel_size=self.config.postnet_kernel_size,\n",
    "            stride=1,\n",
    "            padding= int((self.config.postnet_kernel_size - 1) / 2),\n",
    "            dilation=1\n",
    "        )\n",
    "        \n",
    "        self.bn_4  = nn.BatchNorm1d(\n",
    "            self.config.postnet_embedding_size\n",
    "        )\n",
    "        \n",
    "        self.dropout_4 = nn.Dropout(self.config.dropout)\n",
    "        \n",
    "        self.conv_5 = nn.Conv1d(\n",
    "            self.config.mel_freq,\n",
    "            self.config.postnet_embedding_size,\n",
    "            kernel_size=self.config.postnet_kernel_size,\n",
    "            stride=1,\n",
    "            padding= int((self.config.postnet_kernel_size - 1) / 2),\n",
    "            dilation=1\n",
    "        )\n",
    "        \n",
    "        self.bn_5  = nn.BatchNorm1d(\n",
    "            self.config.postnet_embedding_size\n",
    "        )\n",
    "        \n",
    "        self.dropout_5 = nn.Dropout(self.config.dropout)\n",
    "        \n",
    "        self.conv_6 = nn.Conv1d(\n",
    "            self.config.mel_freq,\n",
    "            self.config.postnet_embedding_size,\n",
    "            kernel_size=self.config.postnet_kernel_size,\n",
    "            stride=1,\n",
    "            padding= int((self.config.postnet_kernel_size - 1) / 2),\n",
    "            dilation=1\n",
    "        )\n",
    "        \n",
    "        self.bn_6  = nn.BatchNorm1d(\n",
    "            self.config.postnet_embedding_size\n",
    "        )\n",
    "        \n",
    "        self.dropout_6 = nn.Dropout(self.config.dropout)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.transpose(2,1)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.bn_1(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.bn_3(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout_3(x)\n",
    "        x = self.conv_4(x)\n",
    "        x = self.bn_4(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout_4(x)\n",
    "        x = self.conv_5(x)\n",
    "        x = self.bn_5(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout_5(x)\n",
    "        x = self.conv_6(x)\n",
    "        x = self.bn_6(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout_6(x)\n",
    "        x = x.transpose(1,2)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderPreNet(nn.Module):\n",
    "    def __init__(self, config : ModelBuildingConfig):\n",
    "        self.config = config \n",
    "        super(DecoderPreNet, self).__init__()\n",
    "        self.linear_1 = nn.Linear(self.config.mel_freq, self.config.embedding_size)\n",
    "        self.linear_2 = nn.Linear(self.config.embedding_size, self.config.embedding_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=True)\n",
    "        x = self.linear_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=True)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.simpletts.components.data_transformation import mask_from_seq_lengths\n",
    "class TransformerTTS(nn.Module):\n",
    "    def __init__(self, config : ModelBuildingConfig, device = 'cuda'):\n",
    "        self.config = config\n",
    "        super(TransformerTTS, self).__init__()\n",
    "        self.encoder_prenet = EncoderPreNet(config)\n",
    "        self.decoder_prenet = DecoderPreNet(config)\n",
    "        self.postnet = PostNet(config)\n",
    "        self.pos_encoder = nn.Embedding(num_embeddings=self.config.max_mel_time, embedding_dim=self.config.embedding_size)\n",
    "        self.encoder_block1 = EncoderBlock(config)\n",
    "        self.encoder_block2 = EncoderBlock(config)\n",
    "        self.encoder_block3 = EncoderBlock(config)\n",
    "        self.decoder_block1 = DecoderBlcok(config)\n",
    "        self.decoder_block2 = DecoderBlcok(config)\n",
    "        self.decoder_block3 = DecoderBlcok(config)\n",
    "        self.linear1 = nn.Linear(self.config.embedding_size, self.config.mel_freq)\n",
    "        self.linear2 = nn.Linear(self.config.embedding_size + 1)\n",
    "        self.norm_memory = nn.LayerNorm(normalized_shape=self.config.embedding_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, text, text_len, mel, mel_len):\n",
    "        N = text.shape[0]\n",
    "        S = text.shape[1]\n",
    "        TIME = mel.shape[1]\n",
    "            \n",
    "        # Create mask\n",
    "        self.src_key_padding_mask = torch.zeros((N, S), device=text.device).masked_fill(\n",
    "        ~mask_from_seq_lengths(text_len, max_length=S), float(\"-inf\")\n",
    "        )\n",
    "        self.src_mask = torch.zeros((S, S), device=text.device).masked_fill(\n",
    "             torch.triu(torch.full((S, S), True, dtype=torch.bool), diagonal=1).to(text.device),       \n",
    "            float(\"-inf\")\n",
    "        )\n",
    "        self.tgt_key_padding_mask = torch.zeros((N, TIME), device=mel.device).masked_fill(\n",
    "            ~mask_from_seq_lengths(mel_len, max_length=TIME), float(\"-inf\")\n",
    "        )\n",
    "        self.tgt_mask = torch.zeros((TIME, TIME), device=mel.device).masked_fill(\n",
    "            torch.triu(torch.full((TIME, TIME), True, device=mel.device, dtype=torch.bool), diagonal=1),       \n",
    "            float(\"-inf\")\n",
    "        )\n",
    "        self.memory_mask = torch.zeros((TIME, S), device=mel.device).masked_fill(\n",
    "            torch.triu(torch.full((TIME, S), True, device=mel.device, dtype=torch.bool), diagonal=1),       \n",
    "            float(\"-inf\")\n",
    "        )\n",
    "            \n",
    "            \n",
    "        # Encoder \n",
    "        text_x = self.encoder_prenet(text)\n",
    "        pos_codes = self.pos_encode(torch.arange(self.config.max_mel_time).to(mel.device))\n",
    "        S = text_x.shape[1]\n",
    "        text_x = text_x + pos_codes[:S]\n",
    "        text_x = self.encoder_block1(text_x, attn_mask = self.src_mask, key_padding_mask = self.src_key_padding_mask)\n",
    "        text_x = self.encoder_block2(text_x, attn_mask = self.src_mask, key_padding_mask = self.src_key_padding_mask)\n",
    "        text_x = self.encoder_block3(text_x, attn_mask = self.src_mask, key_padding_mask = self.src_key_padding_mask)\n",
    "        text_x = self.norm_memory(text_x)\n",
    "        \n",
    "        # Decoder \n",
    "        mel_x = self.decoder_prenet(mel)\n",
    "        mel_x = mel_x + pos_codes[:TIME]\n",
    "        mel_x = self.decoder_block1(x  = mel_x, memory = text_x, x_attn_mask = self.tgt_mask,\n",
    "                                    x_key_padding_mask = self.tgt_key_padding_mask,\n",
    "                                    memory_key_padding_mask = self.src_key_padding_mask)\n",
    "        mel_x = self.decoder_block2(x  = mel_x, memory = text_x, x_attn_mask = self.tgt_mask,\n",
    "                                    x_key_padding_mask = self.tgt_key_padding_mask,\n",
    "                                    memory_key_padding_mask = self.src_key_padding_mask)\n",
    "        mel_x = self.decoder_block3(x  = mel_x, memory = text_x, x_attn_mask = self.tgt_mask,\n",
    "                                    x_key_padding_mask = self.tgt_key_padding_mask,\n",
    "                                    memory_key_padding_mask = self.src_key_padding_mask)\n",
    "        \n",
    "        \n",
    "        # Output Processing\n",
    "        mel_linear = self.linear1(mel_x)\n",
    "        mel_postnet = self.postnet(mel_linear)\n",
    "        mel_postnet = mel_linear + mel_postnet\n",
    "        stop_token = self.linear2(mel_x)\n",
    "        \n",
    "        \n",
    "        # Masking \n",
    "        bool_mel_mask = self.tgt_key_padding_mask.ne[0].unsqueeze(-1).repeat(1,1,self.config.mel_freq)\n",
    "        mel_linear = mel_linear.masked_fill(bool_mel_mask, 0)\n",
    "        mel_postnet = mel_postnet.masked_fill(bool_mel_mask, 0)\n",
    "        stop_token = stop_token.masked_fill(bool_mel_mask[:, :, 0].unsqueeze(-1).squeeze(2))\n",
    "        return mel_postnet, mel_linear, stop_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-03 02:31:40,414: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-09-03 02:31:40,417: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-09-03 02:31:40,419: INFO: common: created directory at: artifacts]\n",
      "[2024-09-03 02:31:40,419: INFO: common: created directory at: artifacts/model]\n"
     ]
    },
    {
     "ename": "BoxKeyError",
     "evalue": "\"'ConfigBox' object has no attribute 'root_dir'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\azizu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\box\\box.py:503\u001b[0m, in \u001b[0;36mBox.__getitem__\u001b[1;34m(self, item, _ignore_default)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'root_dir'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBoxKeyError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\azizu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\box\\box.py:536\u001b[0m, in \u001b[0;36mBox.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_ignore_default\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\azizu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\box\\box.py:524\u001b[0m, in \u001b[0;36mBox.__getitem__\u001b[1;34m(self, item, _ignore_default)\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_default(item)\n\u001b[1;32m--> 524\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BoxKeyError(\u001b[38;5;28mstr\u001b[39m(err)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_exception_cause\u001b[39;00m(err)\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mBoxKeyError\u001b[0m: \"'root_dir'\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\azizu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\box\\box.py:538\u001b[0m, in \u001b[0;36mBox.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 538\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ConfigBox' object has no attribute 'root_dir'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBoxKeyError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\azizu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\box\\config_box.py:28\u001b[0m, in \u001b[0;36mConfigBox.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\azizu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\box\\box.py:552\u001b[0m, in \u001b[0;36mBox.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_default(item, attr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 552\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BoxKeyError(\u001b[38;5;28mstr\u001b[39m(err)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_exception_cause\u001b[39;00m(err)\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[1;31mBoxKeyError\u001b[0m: \"'ConfigBox' object has no attribute 'root_dir'\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\azizu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\box\\box.py:503\u001b[0m, in \u001b[0;36mBox.__getitem__\u001b[1;34m(self, item, _ignore_default)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'root_dir'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBoxKeyError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\azizu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\box\\box.py:536\u001b[0m, in \u001b[0;36mBox.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_ignore_default\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\azizu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\box\\box.py:524\u001b[0m, in \u001b[0;36mBox.__getitem__\u001b[1;34m(self, item, _ignore_default)\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_default(item)\n\u001b[1;32m--> 524\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BoxKeyError(\u001b[38;5;28mstr\u001b[39m(err)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_exception_cause\u001b[39;00m(err)\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mBoxKeyError\u001b[0m: \"'root_dir'\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\azizu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\box\\box.py:538\u001b[0m, in \u001b[0;36mBox.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m--> 538\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ConfigBox' object has no attribute 'root_dir'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBoxKeyError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize ConfigurationManager\u001b[39;00m\n\u001b[0;32m      6\u001b[0m config_manager \u001b[38;5;241m=\u001b[39m ConfigurationManager()\n\u001b[1;32m----> 7\u001b[0m model_config \u001b[38;5;241m=\u001b[39m \u001b[43mconfig_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_building_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m TransformerTTS(model_config)\n",
      "Cell \u001b[1;32mIn[16], line 21\u001b[0m, in \u001b[0;36mConfigurationManager.get_model_building_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     17\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel_building\n\u001b[0;32m     18\u001b[0m create_directories([config\u001b[38;5;241m.\u001b[39mroot_dir])\n\u001b[0;32m     20\u001b[0m model_building_config \u001b[38;5;241m=\u001b[39m ModelBuildingConfig(\n\u001b[1;32m---> 21\u001b[0m     root_dir\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_dir\u001b[49m,\n\u001b[0;32m     22\u001b[0m     text_num_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mtext_num_embeddings,\n\u001b[0;32m     23\u001b[0m     embedding_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39membedding_size,\n\u001b[0;32m     24\u001b[0m     encoder_embedding_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mencoder_embedding_size,\n\u001b[0;32m     25\u001b[0m     dim_feedforward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mdim_feedforward,\n\u001b[0;32m     26\u001b[0m     postnet_embedding_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mpostnet_embedding_size,\n\u001b[0;32m     27\u001b[0m     encoder_kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mencoder_kernel_size,\n\u001b[0;32m     28\u001b[0m     postnet_kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mpostnet_kernel_size,\n\u001b[0;32m     29\u001b[0m     dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mdorout,\n\u001b[0;32m     30\u001b[0m     num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[0;32m     31\u001b[0m     batch_first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mbatch_first,\n\u001b[0;32m     32\u001b[0m     mel_freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mmel_freq,\n\u001b[0;32m     33\u001b[0m     max_mel_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mmax_mel_time\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_building_config\n",
      "File \u001b[1;32mc:\\Users\\azizu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\box\\config_box.py:30\u001b[0m, in \u001b[0;36mConfigBox.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(item)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\azizu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\box\\box.py:552\u001b[0m, in \u001b[0;36mBox.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m BoxKeyError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Does not exist and internal methods are never defaulted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_default(item, attr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 552\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BoxKeyError(\u001b[38;5;28mstr\u001b[39m(err)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_exception_cause\u001b[39;00m(err)\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[1;31mBoxKeyError\u001b[0m: \"'ConfigBox' object has no attribute 'root_dir'\""
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize ConfigurationManager\n",
    "config_manager = ConfigurationManager()\n",
    "model_config = config_manager.get_model_building_config()\n",
    "\n",
    "# Initialize the model\n",
    "model = TransformerTTS(model_config)\n",
    "\n",
    "# Print and save model summary\n",
    "def print_and_save_summary(model, input_size, file_path):\n",
    "    model_summary = summary(model, input_size=input_size, depth=10, col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"])\n",
    "    print(model_summary)\n",
    "    \n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(str(model_summary))\n",
    "    print(f\"Model summary saved to {file_path}\")\n",
    "\n",
    "# Example input sizes (you may need to adjust these based on your specific configuration)\n",
    "text_input_size = (1, 100)  # (batch_size, sequence_length)\n",
    "text_len_input_size = (1,)\n",
    "mel_input_size = (1, model_config.max_mel_time, model_config.mel_freq)\n",
    "mel_len_input_size = (1,)\n",
    "\n",
    "input_size = (text_input_size, text_len_input_size, mel_input_size, mel_len_input_size)\n",
    "\n",
    "# Define the file path for saving the summary\n",
    "summary_file_path = Path(model_config.root_dir) / \"model_summary.txt\"\n",
    "\n",
    "# Print and save the model summary\n",
    "print_and_save_summary(model, input_size, summary_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\azizu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\azizu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\azizu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
